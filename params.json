{"note":"Don't delete this file! It's used internally to help with page regeneration.","google":"","tagline":"Cloud Rapid Experimentation and Analysis Toolkit","name":"cbtool","body":"INTRODUCTION:\r\n=============\r\n\r\nCloud Rapid Experimentation and Analysis Tool is a framework that automates IaaS cloud benchmarking through the running of controlled experiments.\r\n\r\nFEATURES:\r\n=========\r\n\r\n* Automatic deployment and controlled execution of multiple multi-tier applications.\r\n* Each individual application can have a specific load profile using probability distributions.\r\n* Adapters for multiple clouds (EC2 and OpenStack, among others), with a plugin structure that allows new cloud models to be added incrementally.\r\n* Can orchestrate different arrival rates and lifetimes for VMs using probability distributions.\r\n* Collects application and system (OS) performance data from hosts and guests in real time.\r\n* It is designed from the ground up to be highly scalable and parallel.\r\n\r\nCONTACTS:\r\n=========\r\n\r\nMarcio A. L. Silva marcios@us.ibm.com\r\n\r\nMichael R. Hines mrhines@us.ibm.com\r\n\r\nQUICKSTART\r\n=========\r\n\r\nIf you are running the tool for the first time, please run ```configure``` first. It will check if all dependencies (e.g., Redis, MongoDB) are properly installed and configured.\r\n\r\nThe tool reads all configuration parameters from a file name ```cloud_definitions.txt``` located on the ```configs``` directory. It is recommended that you make a copy of this file (on the same directory),\r\nnaming it ```<you username>_cloud_definitions.txt```.\r\n\r\nTo run the tool's CLI, use ```cb```. Initially, you will see an empty prompt, ```()```, indicating that there is no\r\ncloud attached to this experiment.\r\n\r\nIn the tool prompt, try to attach a simulated cloud using the command ```cldattach sim TESTCLOUD```. You will you see that now the prompt changes to ```(TESCLOUD)```.\r\n\r\nAfter that, attach all simulated hosts defined on the configuration file with the command ```vmcattach all```. List all simulated HOSTS on this cloud with the command ```hostlist```.\r\n\r\nAt this point you can create some simple simulated VMs with the command ```vmattach db2``` or ```vmattach was```. Make sure all simulated VMs are created with the command ```vmlist```.\r\n\r\nAll ```<object>attach``` commands block the CLI during its execution. Since some commands (e.g., ```aiattach```) can take quite a bit of time to complete, the keyword ```async``` can be appended at the end of the command to allow its execution in background. For instance, while deploying a DayTrader Virtual Application with the command ```aiattach daytrader``` would block the CLI for several minutes (depending on the cloud), the command ```aiattach daytrader async``` would return immediately, leaving a daemon executing the deployment in the background.\r\n\r\nThe purpose of starting  with a simulated cloud is to make sure that everything is working properly within the tool *before* starting to use the tool against a real cloud.\r\n\r\nTo exit, use the ```exit``` command. You can exit and restart the tool at any moment; the data/state is stored on an ```Object Store``` (Redis server) that is accessed by the CLI.\r\n\r\nWhenever a CLI is started, a web GUI daemon is also started. Just point your browser to the port indicated at the tool's CLI prompt (look for \"GUI Service daemon was successfully started\"), and then click on the ```Connect``` button on the top.\r\n\r\nREPORTING BUGS:\r\n===============\r\n\r\nThe tools writes all logs to a folder located @ \"stores/logs\". When you run into a bug, please packup the logs folder and send it to us and we'll work with you to get it fixed.\r\n\r\nWe would also like to start using github's bug tracking system: You could post all the details of your issue there - that would be very helpful.\r\n\r\nUSING THE TOOL IN A REAL CLOUD\r\n============================\r\n\r\nCurrently the tool supports the following Clouds:\r\n\r\n* OpenStack\r\n* Amazon EC2\r\n* IBM Smart Cloud Provisioning\r\n* Thin Agile Cloud (barebones tool based on libvirt/KVM, used internally)\r\n\r\nAll aspects of VApp deployment are automated. The tool will know which VMs to create (based on a VApp template), and will contact the cloud management system directly to carry out the creation.\r\nAfter the VMs are started, it logins on the VMs (through SSH), configures the applications and starts a load manager daemon. At this point, ```management metrics``` (e.g., image creation time, boot time) are collected.\r\nDuring the whole VApp lifecycle, application and OS ```runtime metrics``` are collected and stored. If the cloud allows direct access to the hosts, their performance data is also collected.\r\nIf the VApp was implicitly deployed by a VApp Submitter, it is automatically removed at the end of its lifetime. If the VApp was explicitly deployed, it has to be removed by the experimenter.\r\n\r\nBefore using the tool in a real cloud, the following steps must be taken:\r\n\r\n1. Add your own pair of ssh keys to the ```credentials``` directory\r\n\r\n2. Prepare your own images to be used with the tool.\r\n    1.  Make sure that the VMs can be contacted through passwordless SSH.\r\n    2.  Make sure that the applications are installed/configured on your VM.\r\n    Unfortunately, at this time we cannot provide pre-configured VMs due to\r\n    licensing issues.\r\n    3.  Copy the tool's code to the VM, and then run \"configure\" there. If the dependencies are installed on the VM, then the VM can be remotely accessed and controlled.\r\n3. Fill out the information required to access the cloud (e.g., account names, credentials) on the configuration file. This file is either ```cloud_definitions.txt``` or preferably ```<your username>_cloud_definitions.txt```\r\n\r\nAfter these steps are taken, go to the section \"RUNNING EXPERIMENTS\" and try to\r\nrun the first experiment (it is short, just type the commands).\r\n\r\nGENERAL DESCRIPTION\r\n===================\r\n\r\nAn ```experiment``` is executed by the deployment and running of a set of ```Virtual Applications``` (VApps). An experiment can be done interactively, having the user typing commands directly on the CLI, or having a series of commands in text format in an ```experiment file```.\r\n\r\nA VApp represents a group of VMs, with different ```roles```, logically connected to execute different application types. For instance, a ```DayTrader VApp``` is composed by one VM with the role \"load driver\", one VM with the role \"application server\" (either Tomcat or WAS) and one VM with the role \"db\"\r\n(either DB2 or MySQL). On other hand a ```Hadoop VApp``` is composed by one VM with the role \"master\" and N VMs with the role \"slave\". To see a list of available VM roles, use the command ```rolelist``` on the CLI. To see a list of VApp types use the command ```typelist```. To see a description of a particular VApp, use the command ```typeshow <vapp type>```.\r\n\r\nEach VApp has its own ```load profile```, with independent load level and load duration. The values for load level and load duration can be set as random distributions, fixed numbers or monotonically increasing/decreasing sequences. The ```load level```, has a meaning that is specific to each VApp type. For\r\ninstance, for a DayTrader Vapp, it represents the number of simultaneous clients on the load generator, while for Hadoop it represents the size of dataset to be sorted.\r\n\r\nVApps can be deployed explicitly by the experimenter or implicitly through one or more ```VApp Submitters```. A submitter deploys Vapps with a given ```pattern```, represented by a certain inter-arrival time and a lifetime (also fixed, distributions or sequences). To see a list of available patterns, use the command ```patternlist``` on the CLI. To see a description of a particular pattern, use the command ```patternshow <submitter pattern>```.\r\n\r\nRUNNING EXPERIMENTS\r\n====================\r\n\r\nFor instance, the following experiment file will create three VMs on an\r\nOpenStack cloud, without generating any application load on it:\r\n\r\n    cldattach osk TESTCLOUD\r\n    clddefault TESTCLOUD\r\n    expid exp1\r\n    vmcattach all\r\n    vmclist\r\n    hostlist\r\n    vmattach db2\r\n    vmattach netperf\r\n    vmlist\r\n    waitfor 4m\r\n    vmdetach all\r\n    monextract all\r\n    clddetach\r\n    exit\r\n\r\nThis second experiment will deploy a single DayTrader VApp on EC2, and will vary\r\nthe load level with a normal distribution with average 10, standard deviation 5,\r\nand maximum and minimal values 1 and 20. It will select a new load level each\r\nminute, and will run for 5 hours.\r\n\r\n    cldattach ec2 TESTCLOUD\r\n    clddefault TESTCLOUD\r\n    expid exp2\r\n    vmcattach all\r\n    vmclist\r\n    typealter daytrader load_level=normalI10I5I1I20\r\n    typealter daytrader load_duration=60\r\n    aiattach daytrader\r\n    waitfor 5h\r\n    aidetach all\r\n    monextract all\r\n    clddetach\r\n    exit\r\n\r\nFinally this third experiment will keep generating new DayTrader and Hadoop\r\nVApps, with a specific arrival rate for each VApp Type. DayTrader VApps will\r\narrive with an inter-arrival time according to an exponential distribution with\r\nan average of 600 seconds (with maximum and minimum values of 200 and 2000\r\nseconds), while Hadoop VApps will arrive with an inter-arrival time according to\r\na uniform distribution with values between 200 and 900 seconds. Also the load\r\nlevel of the VApp Hadoop is set to be fixed in 9, while the lifetime is fixed to\r\nbe 7200 seconds. Finally, no more than 40 DayTrader VApps should be created,\r\nand we should wait until the number of created VApps is equal to 100, and the\r\nwait for 5 more hours.\r\n\r\n    cldattach scp TESTCLOUD\r\n    clddefault TESTCLOUD\r\n    expid exp3\r\n    vmcattach all\r\n    vmclist\r\n    patternlist\r\n    patternshow simpledt\r\n    patternalter simpledt iait=exponentialI600IXI200I2000\r\n    patternalter simpledt max_ais=40\r\n    patternshow simpledt\r\n    patternshow simplehd\r\n    patternalter simplehd iait=uniformIXIXI200I900\r\n    patternalter simplehd load_level=9\r\n    patternshow simplehd lifetime=7200\r\n    patternshow simplehd\r\n    aidrsattach simpledt\r\n    aidrsattach simplehd\r\n    waituntil AI ARRIVED=100\r\n    aidrsdetach all\r\n    waituntil AI ARRIVING=0\r\n    ailist\r\n    waitfor 5h\r\n    aidetach all\r\n    monextract all\r\n    clddetach\r\n    exit\r\n\r\nDATA EXTRACTION AND ANALYSIS\r\n============================\r\n\r\nThe command \"monextract all\" will create four different comma-separated value\r\nfiles:\r\n\r\n1. ```VM_management_<experiment id>.csv```: contains information regarding the provisioning time, capture time, among others, all extracted directly from the cloud management system.\r\n2. ```VM_runtime_app_<experiment id>.csv```: contains information regarding the application performance, such as latency, throughput and bandwidth, all generated directly from the VM.\r\n3. ```VM_runtime_os_<experiment id>.csv```: contains OS metrics (CPU, memory, disk I/O, network I/O) all generated by the VM.\r\n4. ```HOST_runtime_os_<experiment id>.csv```: contains OS metrics (CPU, memory, disk I/O, network I/O) all generated by the HOSTS. It can only be used on  Clouds where there is direct access to the hosts (this means that this data cannot be collected on EC2, for instance), and where the Ganglia monitoring tool was manually configured on the hosts.\r\n\r\nA small script (called cbp.R), written in the R language, is available in the ```util/plot``` directory, and can be used to quickly and automatically produce plots using the data supplied by the csv files.\r\n\r\nWrite Client code against the tool's API\r\n=========================================\r\n\r\nThis toolkit provides API for client programming in 3 different languages using XML-RPC to be used to direct benchmarks and algorithms against the API for maximum flexibility.\r\n\r\nAdditionally, these bindings also provide accessor methods for retrieving data from the mongodb database which the tool uses to store monitoring data.\r\n\r\nTypically, upon starting up the tool, an \"API Service\" (xmlrpc server) is started on port 7070.\r\n\r\nIn order to use it, you would choose a language:\r\n\r\n1. Python: from import api_service_client import *\r\n2. Java: import api.*;\r\n3. Ruby: require 'api_service_client'\r\n4. C++: #include \"apl_service_client.hpp\";\r\n\r\nAPI Client Examples in each language:\r\n=========\r\n1. Python: clients/provision_vm.py, clients/provision_application.py\r\n2. Java: clients/ProvisionVM.java, clients/ProvisionAPP.java\r\n3. Ruby: clients/provision_vm.rb, clients/provision_application.rb\r\n4. C++: clients/provision_vm.cpp, clients/provision_application.cpp, clients/list_regions.cpp\r\n\r\nThese examples are fairily self-explanatory. If you help or would like bindings written in a new language, don't hesitate to contact us and we'll try to accomodate you."}